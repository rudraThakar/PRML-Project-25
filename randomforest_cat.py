# -*- coding: utf-8 -*-
"""RANDOMFORESTCAT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CYrorbfrsqk88Q2WejoBiIDnOY6DSCwp
"""

# Prediction Code (Categories) - Using New Scaler with 416 Features and Trivial Names
import joblib
import numpy as np
import pandas as pd
from datetime import datetime
from sentence_transformers import SentenceTransformer

# Load the saved models and preprocessors
categoryLabelEncoder = joblib.load("label_encoder_category.pkl")
randomForestModel = joblib.load("rf_model.pkl")
websiteEncoder = joblib.load("web_encoder_fake.pkl")
featureScaler = joblib.load("scaler_fake_rfcat.pkl")  # Use the new scaler

def getDateFeatures(monthYearString):
    try:
        parsedDate = pd.to_datetime(monthYearString, format='%b-%y')
        return pd.Series({
            'year': parsedDate.year,
            'month': parsedDate.month,
            'quarter': parsedDate.quarter
        })
    except:
        print("Error parsing date")
        return pd.Series({'year': 0, 'month': 0, 'quarter': 0})

def prepareInputFeatures(newsStatement, websiteName, dateString):
    # STEP 1: Generate text embeddings
    textEmbeddingModel = SentenceTransformer('paraphrase-MiniLM-L6-v2')
    textFeatures = textEmbeddingModel.encode([newsStatement])  # Shape: (1, 384)

    # STEP 2: Extract date components
    dateComponents = getDateFeatures(dateString)
    cleanedDateComponents = dateComponents.fillna(0)
    dateFeatures = cleanedDateComponents.values.reshape(1, -1)  # Shape: (1, 3)

    # STEP 3: Encode website source
    websiteDataFrame = pd.DataFrame([[websiteName]], columns=['web'])
    try:
        websiteFeatures = websiteEncoder.transform(websiteDataFrame).toarray()  # Shape: (1, n_web_categories)
    except ValueError:
        websiteFeatures = np.zeros((1, len(websiteEncoder.categories[0])))

    # STEP 4: Combine all features
    combinedFeatures = np.hstack([
        textFeatures,        # 384 features
        websiteFeatures,     # n_web_categories (likely 29 to total 416)
        dateFeatures         # 3 features
    ])

    # STEP 5: Ensure correct feature count
    requiredFeatureCount = randomForestModel.n_features_in_  # Should be 416
    actualFeatureCount = combinedFeatures.shape[1]

    if actualFeatureCount != requiredFeatureCount:
        if actualFeatureCount < requiredFeatureCount:
            paddingZeros = np.zeros((1, requiredFeatureCount - actualFeatureCount))
            combinedFeatures = np.hstack([combinedFeatures, paddingZeros])
        elif actualFeatureCount > requiredFeatureCount:
            combinedFeatures = combinedFeatures[:, :requiredFeatureCount]

    # STEP 6: Scale features
    cleanedFeatures = np.nan_to_num(combinedFeatures, nan=0.0)
    scaledFeatures = featureScaler.transform(cleanedFeatures)

    return scaledFeatures

def predictNewsCategory(newsStatement, websiteName, dateString):
    preparedFeatures = prepareInputFeatures(newsStatement, websiteName, dateString)
    probabilityScores = randomForestModel.predict_proba(preparedFeatures)
    topPredictionIndex = np.argmax(probabilityScores)
    predictedCategory = categoryLabelEncoder.inverse_transform([topPredictionIndex])[0]
    predictionConfidence = probabilityScores[0][topPredictionIndex]
    return predictedCategory, predictionConfidence

# Example usage
newsText = "Covid 19 is evidently increasing"
sourceWebsite = "Mint"
publicationDate = "Jan-21"
category, confidence = predictNewsCategory(newsText, sourceWebsite, publicationDate)
print(f"Prediction: {category} (Confidence: {confidence:.4f})")