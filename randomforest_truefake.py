# -*- coding: utf-8 -*-
"""RANDOMFORESTBINARY.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zd7isO4AuKtVlzlPvQ9U3u5SCuwZkxsu
"""

import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn.utils import resample

class CustomRandomForest:
    def __init__(self, numTrees=10, maxFeatures='sqrt', maxTreeDepth=None, seed=None):
        self.numTrees = numTrees
        self.maxFeatures = maxFeatures  # 'sqrt', 'log2', or int
        self.maxTreeDepth = maxTreeDepth
        self.seed = seed
        self.forest = []

    def getNumSelectedFeatures(self, totalFeatures):
        if self.maxFeatures == 'sqrt':
            return int(np.sqrt(totalFeatures))
        elif self.maxFeatures == 'log2':
            return int(np.log2(totalFeatures))
        elif isinstance(self.maxFeatures, int):
            return self.maxFeatures
        else:
            return totalFeatures

    def fit(self, trainFeatures, trainLabels):
        np.random.seed(self.seed)
        self.forest = []

        for treeIndex in range(self.numTrees):
            bootFeatures, bootLabels = resample(
                trainFeatures,
                trainLabels,
                replace=True,
                random_state=self.seed + treeIndex if self.seed else None
            )

            totalFeatures = trainFeatures.shape[1]
            numSelectedFeatures = self.getNumSelectedFeatures(totalFeatures)
            selectedFeatureIndices = np.random.choice(totalFeatures, numSelectedFeatures, replace=False)

            decisionTree = DecisionTreeClassifier(max_depth=self.maxTreeDepth, random_state=self.seed)
            decisionTree.fit(bootFeatures[:, selectedFeatureIndices], bootLabels)

            self.forest.append((decisionTree, selectedFeatureIndices))

    def predictProba(self, testFeatures):
        allProbabilities = []

        for decisionTree, featureIndices in self.forest:
            probs = decisionTree.predict_proba(testFeatures[:, featureIndices])
            allProbabilities.append(probs)

        averageProbs = np.mean(allProbabilities, axis=0)
        return averageProbs

    def predict(self, testFeatures):
        averageProbs = self.predictProba(testFeatures)
        return np.argmax(averageProbs, axis=1)

import joblib
import numpy as np
import pandas as pd
from sentence_transformers import SentenceTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler

import warnings
warnings.filterwarnings("ignore", category=UserWarning)

# Load models and encoders
rfModel = joblib.load("custom_rf.pkl")
webEncoder = joblib.load("web_encoder_fake.pkl")
scaler = joblib.load("scaler_fake.pkl")
bertModel = SentenceTransformer('paraphrase-MiniLM-L6-v2')

def extractDateFeatures(monthYearStr):
    try:
        date = pd.to_datetime(monthYearStr, format='%b-%y')
        return pd.Series({
            'year': date.year,
            'month': date.month,
            'quarter': date.quarter
        })
    except:
        return pd.Series({'year': 0, 'month': 0, 'quarter': 0})

def preprocessInput(statement, web, dateStr):
    bertEmbed = bertModel.encode([statement])  # Shape: (1, 384)
    dateFeat = extractDateFeatures(dateStr).fillna(0).values.reshape(1, -1)  # Shape: (1, 3)
    webEncoded = webEncoder.transform([[web]])  # Shape: (1, 28)

    finalFeatures = np.hstack([bertEmbed, webEncoded, dateFeat])
    finalFeatures = np.nan_to_num(finalFeatures, nan=0.0)

    expectedFeatures = scaler.mean_.shape[0]
    currentFeatures = finalFeatures.shape[1]

    if currentFeatures > expectedFeatures:
        finalFeatures = finalFeatures[:, :expectedFeatures]
    elif currentFeatures < expectedFeatures:
        padding = np.zeros((1, expectedFeatures - currentFeatures))
        finalFeatures = np.hstack([finalFeatures, padding])

    return scaler.transform(finalFeatures)

def predictRF(statement, web, date):
    inputVec = preprocessInput(statement, web, date)
    prob = rfModel.predictProba(inputVec)
    prediction = np.argmax(prob)
    labelMap = {0: "Fake", 1: "True"}
    return labelMap[prediction], prob[0][prediction]

# Example usage
statement = "PM to give important speech tomorrow"
webSource = "NDTV"
publishDate = "Jan-21"

label, confidence = predictRF(statement, webSource, publishDate)
print("Prediction:", label, "(Confidence:", f"{confidence:.4f})")