# -*- coding: utf-8 -*-
"""naive_bayes_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ydLV--M-Pi4p3CwqmJegCMw2Fez4A-oH
"""

import numpy as np
from collections import defaultdict

class SimpleNaiveBayes:
    def fit(self, X, y):
        self.classes = np.unique(y)
        self.class_probs = {}
        self.feature_stats = {}

        for c in self.classes:
            X_c = X[y == c]
            self.class_probs[c] = X_c.shape[0] / X.shape[0]
            self.feature_stats[c] = {
                "mean": np.mean(X_c, axis=0),
                "var": np.var(X_c, axis=0) + 1e-6  # to avoid division by zero
            }

    def calculate_prob(self, class_val, x):
        mean = self.feature_stats[class_val]["mean"]
        var = self.feature_stats[class_val]["var"]
        numerator = np.exp(- (x - mean) ** 2 / (2 * var))
        denominator = np.sqrt(2 * np.pi * var)
        probs = numerator / denominator
        return np.prod(probs) * self.class_probs[class_val]

    def predict(self, X):
        preds = []
        for x in X:
            class_probs = {c: self.calculate_prob(c, x) for c in self.classes}
            best_class = max(class_probs, key=class_probs.get)
            preds.append(best_class)
        return np.array(preds)

import joblib
import numpy as np
import pandas as pd
from sentence_transformers import SentenceTransformer

# Load components
category_model = joblib.load("naive_bayes_category_model.pkl")
category_vectorizer = joblib.load("category_vectorizer.pkl")
category_encoder = joblib.load("category_label_encoder.pkl")

label_model = joblib.load("naive_bayes_label_model.pkl")
web_encoder = joblib.load("web_encoder_fake.pkl")
scaler = joblib.load("scaler_fake.pkl")

bertModel = SentenceTransformer('paraphrase-MiniLM-L6-v2')

# --- Utility Functions ---

def extractDateFeatures(monthYearStr):
    try:
        date = pd.to_datetime(monthYearStr, format='%b-%y')
        return pd.Series({
            'year': date.year,
            'month': date.month,
            'quarter': date.quarter
        })
    except:
        return pd.Series({'year': 0, 'month': 0, 'quarter': 0})

def preprocessLabelInput(statement, web, dateStr):
    bertEmbed = bertModel.encode([statement])  # Shape: (1, 384)
    dateFeat = extractDateFeatures(dateStr).fillna(0).values.reshape(1, -1)
    webEncoded = web_encoder.transform(pd.DataFrame([[web]], columns=['Web']))
    webEncoded = webEncoded*0.1

 # One-hot encoded shape (1, N)

    finalFeatures = np.hstack([bertEmbed, webEncoded, dateFeat])
    finalFeatures = np.nan_to_num(finalFeatures, nan=0.0)

    # Padding or trimming to expected input size
    expectedFeatures = scaler.mean_.shape[0]
    if finalFeatures.shape[1] < expectedFeatures:
        padding = np.zeros((1, expectedFeatures - finalFeatures.shape[1]))
        finalFeatures = np.hstack([finalFeatures, padding])
    else:
        finalFeatures = finalFeatures[:, :expectedFeatures]

    return scaler.transform(finalFeatures)

# --- Final Prediction Function ---
def predictNB(statement, web, date):
    # Changed 'preprocessInput' to 'preprocessLabelInput'
    inputVec = preprocessLabelInput(statement, web, date)

    # Predict Category
    category_probs = category_model.predict_proba(category_vectorizer.transform([statement]))[0]
    category_index = np.argmax(category_probs)
    category_label = category_encoder.inverse_transform([category_index])[0]
    category_confidence = category_probs[category_index]

    # Predict Label
    label_index = label_model.predict(inputVec)[0]
    label_prob_true = label_model.calculate_prob(1, inputVec[0])
    label_prob_fake = label_model.calculate_prob(0, inputVec[0])
    total = label_prob_true + label_prob_fake
    if total == 0 or np.isnan(total) or np.isinf(total):
     label_confidence = 0.0
    else:
     label_confidence = label_prob_true / total if label_index == 1 else label_prob_fake / total

    label_text = "True" if label_index == 1 else "Fake"

    # Print results
    print(f" Category = {category_label} (Confidence: {category_confidence:.4f})")
    print(f" Label = {label_text} (Confidence: {label_confidence:.4f})")

    # Return results
    return {
        "Category": category_label,
        "Category Confidence": round(category_confidence, 4),
        "Label": label_text,
        "Label Confidence": round(label_confidence, 4)
    }

# Example usage
statement = "WHO praises India's Aarogya Setu app, says it helped in identifying COVID-19 clusters"
webSource = "NDTV"
publishDate = "Jan-21"

# The function called should be 'predictNB' not 'predictNaiveBayes'
result = predictNB(statement, webSource, publishDate)